ğŸ§ª QA AI Agent
Offline AI-Powered QA Assistant with RAG using Ollama & ChromaDB
An open-source, fully local QA AI Agent designed to assist QA Engineers and Test Automation teams by generating, analyzing, storing, and retrieving QA knowledge using Retrieval-Augmented Generation (RAG).
âœ… No OpenAI API
âœ… No paid services
âœ… Runs fully offline
âœ… Uses open-source LLMs

ğŸš€ Key Features
ğŸ¤– Local LLM via Ollama (LLaMA 3 / Mistral)
ğŸ§  RAG (Retrieval-Augmented Generation)
ğŸ“¦ Vector Database (ChromaDB)
ğŸ” Semantic search for QA knowledge
ğŸ§ª Test case review & generation
ğŸ Bug analysis
ğŸ“„ Log analysis
ğŸ“‹ QA checklist creation
ğŸ” Hallucination-safe answers (context enforced)

Architecture Flow
User Input (QA Question)
        â†“
Vector Database (ChromaDB)
        â†“
Relevant QA Context (Semantic Search)
        â†“
Context Injection (RAG Prompt)
        â†“
Local LLM (Ollama - LLaMA3)
        â†“
Final Grounded QA Answer


Project Structure
qa-ai-agent/
â”‚
â”œâ”€â”€ agent/
â”‚   â”œâ”€â”€ qa_agent.py          # Core QA agent logic
â”‚   â”œâ”€â”€ ollama_client.py     # Ollama LLM client
â”‚   â”œâ”€â”€ vector_store.py      # ChromaDB vector operations
â”‚   â”œâ”€â”€ prompts.py           # System & RAG prompts
â”‚
â”œâ”€â”€ .env                     # Environment variables
â”œâ”€â”€ main.py                  # CLI entry point
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ README.md                # Project documentation

Core Components Explained
1ï¸âƒ£ Ollama (Local LLM Engine)
Runs open-source LLMs locally
No API keys required
Example models:
a. llama3
b. mistral

2ï¸âƒ£ ChromaDB (Vector Database)
Stores QA knowledge as embeddings
Enables semantic similarity search
Fully local & lightweight

3ï¸âƒ£ RAG Layer (Context Injection)
Retrieves relevant QA data
Injects it into LLM prompts
Prevents hallucinations
Ensures project-specific answers

RAG Prompt Strategy
The agent only answers using retrieved context:
If the answer is not present in the context,
respond with: "Not found in knowledge base"
This makes the agent QA-safe and reliable.

ğŸ› ï¸ Installation
1ï¸âƒ£ Install Ollama
brew install ollama
brew services start ollama
Verify:
ollama --version
Pull model:
ollama pull llama3

2ï¸âƒ£ Setup Python Environment
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

3ï¸âƒ£ Run the Agent
python main.py
ğŸ§ª Example RAG Question
What login-related issues were found earlier?
âœ” Searches QA memory
âœ” Injects real bug/test/log context
âœ” Produces grounded answer


Why This Project Is Special =>
| Feature      | Cloud AI | This Project |
| ------------ | -------- | ------------ |
| Offline      | âŒ        | âœ…            |
| Free         | âŒ        | âœ…            |
| Private Data | âŒ        | âœ…            |
| RAG          | âš ï¸        | âœ…            |
| QA-Specific  | âŒ        | âœ…            |

ğŸ§­ Roadmap
ğŸ“‚ Upload Jira tickets / PRDs / logs (PDF, TXT)
ğŸŒ Web UI using FastAPI
ğŸ§  Auto-learning from test execution results
ğŸ“Š Confidence score per answer
ğŸ§ª CI/CD pipeline integration
ğŸ”„ Multi-project vector isolation

ğŸ¤ Contributing
Contributions are welcome!
Feel free to:
Add new QA tools
Improve prompts
Enhance RAG logic
Add UI layers

ğŸ“œ License
MIT License â€“ Free to use, modify, and distribute.

ğŸ™Œ Author
Sayan Koley
QA Automation | AI in Testing | Open Source
